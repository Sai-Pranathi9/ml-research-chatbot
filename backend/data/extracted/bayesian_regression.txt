1
Statistical Anomaly Detection via Composite
Hypothesis Testing for Markov Modelsâˆ—
Jing Zhangâ€ , Student Member, IEEE, and Ioannis Ch. Paschalidisâ€¡, Fellow, IEEE
Abstract
Under Markovian assumptions, we leverage a Central Limit Theorem (CLT) for the empirical measure in the test
statistic of the composite hypothesis Hoeffding test so as to establish weak convergence results for the test statistic,
and, thereby, derive a new estimator for the threshold needed by the test. We ï¬rst show the advantages of our estimator
over an existing estimator by conducting extensive numerical experiments. We ï¬nd that our estimator controls better
for false alarms while maintaining satisfactory detection probabilities. We then apply the Hoeffding test with our
threshold estimator to detecting anomalies in two distinct applications domains: one in communication networks and
the other in transportation networks. The former application seeks to enhance cyber security and the latter aims at
building smarter transportation systems in cities.
Index Terms
Hoeffding test, weak convergence, false alarm rate, Markov chains, network anomaly detection, cyber security,
non-typical trafï¬c jams, smart cities.
I. INTRODUCTION
For a given system, Statistical Anomaly Detection (SAD) involves learning from data the normal behavior of
the system and identifying/reporting time instances corresponding to atypical system behavior. SAD has vast
applications. For instance, motivated by the importance of enhancing cyber security, recent literature has seen
applications in communication networks; see, e.g., [1], [2], [3], [4]. The behavior of the system is typically
represented as a time series of real vectors and, in its most general version, anomaly detection is done through
some Composite Hypothesis Test (CHT).
Speciï¬cally, a CHT aims to test the hypothesis that a given sequence of observations is drawn from a known
Probability Law (PL) (i.e., probability distribution) deï¬ned on a ï¬nite alphabet [5]. Among numerous such tests,
the one proposed by Hoeffding [6] has been well known for decades. When implementing the Hoeffding test in the
* Submitted to IEEE Transactions on Signal Processing. Research partially supported by the NSF under grants CNS-1645681, CCF-1527292,
and IIS-1237022, by the ARO under grants W911NF-11-1-0227 and W911NF-12-1-0390, and by a grant from the Boston Area Research
Initiative (BARI).
â€  Division of Systems Engineering, Boston University, Boston, MA 02446, email: jzh@bu.edu.
â€¡ Division of Systems Engineering, Dept. of Electrical and Computer Engineering, and Dept. of Biomedical Engineering, Boston University.
8 St. Maryâ€™s St., Boston, MA 02215, email: yannisp@bu.edu, url: http://sites.bu.edu/paschalidis.
August 22, 2017
DRAFT
arXiv:1702.08435v3  [cs.SY]  18 Aug 2017
2
context of SAD, one must set appropriately a threshold Î· so as to ensure a low false alarm rate while maintaining
a reasonably high detection rate. In the existing literature, this threshold is typically estimated by using Sanovâ€™s
theorem [7] â€“ a large deviations result. Note that such an estimator (let us denote it by Î·sv) is valid only in the
asymptotic sense. In practice, however, only a ï¬nite number of observations are available, and it can be observed
in simulations that Î·sv is not accurate enough, especially for relatively small sample sizes.
Our contributions in this paper include:
1) Under Markovian assumptions, we leverage a Central Limit Theorem (CLT) for a selected empirical measure
related to the test statistic of the Hoeffding test, so as to establish weak convergence results for the test
statistic, and derive a threshold estimator Î·wc therefrom, thus, extending the work of [5] which tackles the
problem under independent and identically distributed (i.i.d.) assumptions.
2) We propose algorithms to calculate the threshold estimator Î·wc obtained above for the ordinary and a robust
version of the Hoeffding test, respectively. We assess the advantages of our estimator over earlier work through
numerical experiments.
3) We apply the Hoeffding test with our threshold estimator to two types of systems for the purpose of anomaly
detection: (i) a communication network with ï¬‚ow data simulated by the software package SADIT [8]; and
(ii) a real transportation network with jam data reported by Waze, a smartphone GPS navigation application.
To the best of our knowledge, the latter is a novel application of anomaly detection.
A preliminary conference version of this work appeared in [9]. The present paper includes detailed technical
arguments, derives results for the robust version of the Hoeffding test, expands the numerical comparisons with
earlier work, and develops the trafï¬c jam anomaly detection application.
The rest of this paper is organized as follows. In Sec. II we review related work. We formulate the threshold
estimation problem in Sec. III and derive theoretical results in Sec. IV. Sec. V contains experimental results.
Concluding remarks are in Sec. VI and a number of proofs appear in the Appendix.
Notational conventions: All vectors are column vectors. For economy of space, we write x = (x1, . . . , xdim(x))
to denote the column vector x, where dim(x) is its dimension. We use prime to denote the transpose of a matrix
or vector. Denote by N+ the set of all nonnegative integers. âˆ¥xâˆ¥denotes the â„“2-norm of a vector x, âŒŠxâŒ‹the integer
part of a positive number x, |A| the cardinality of a set A, log the natural logarithm, P(A) the probability of an
event A, E[X] the expectation of a random variable X, and Cov(X1, X2) the covariance between two random
variables X1 and X2. We use N(0, Î£) to denote a Gaussian distribution with zero mean and covariance matrix
Î£. X1 â‰ƒX2 indicates that the two random variables X1 and X2 have approximately the same distribution. 1{Â·}
denotes the indicator function and
d
âˆ’âˆ’âˆ’âˆ’â†’
nâ†’âˆ(resp.,
w.p.1
âˆ’âˆ’âˆ’âˆ’â†’
nâ†’âˆ) denotes convergence in distribution (resp., with probability
one) as n approaches inï¬nity.
II. RELATED WORK
Modeling network trafï¬c as stationary in time, [1] applies two methods: one assumes the trafï¬c to be an i.i.d.
sequence and the other assumes observations of system activity follow a ï¬nite-state Markov chain. Both methods are
extended in [4] to the case where system activity is time-varying. When implementing the Hoeffding test, however,
August 22, 2017
DRAFT
3
both [1] and [4] use the large deviations estimator Î·sv to calculate the detection threshold in a ï¬nite sample-size
setting, thus controlling the false alarm rate not well enough.
To derive a more accurate threshold estimator, [5], [10] use a procedure commonly used by statisticians: deriving
results based on Weak Convergence (WC) of the test statistic in order to approximate the error probabilities of the
Hoeffding test. Under i.i.d. assumptions, [5] (see also [10], [11]) proposes an alternative estimator for Î· (let us
denote it by Î·wc), which is typically more accurate than Î·sv, especially when not that many samples are available.
There has also been work on obtaining a tighter approximation of Î· by reï¬ning Sanovâ€™s theorem [12]. However,
such reï¬nements of large deviation results are typically faced with computational difï¬culty; for instance, as noted
in [10], using the results of [12] requires the computation of a surface integral.
Several alternative anomaly detection approaches have been proposed, using for instance change detection
methods [13]. We refer the reader for a comprehensive review of alternative methods to [13] and [1].
III. PROBLEM FORMULATION
To model the statistical properties of a general system, we introduce a few more notational conventions and some
deï¬nitions. Let Î = {Î¾i; i = 1, . . . , N} be a ï¬nite alphabet containing N symbols Î¾1, . . . , Î¾N, and Y = {Yl; l =
0, 1, 2, . . .} a time series of observations. Deï¬ne the null hypothesis H as: Y is drawn according to a Markov chain
with state set Î and transition matrix Q = [qij]N
i, j=1. To further characterize the stochastic properties of Y, we
deï¬ne the empirical Probability Law (PL) by
Î“n(Î¸ij) = 1
n
n
X
l=1
1{Zl = Î¸ij},
(1)
where Zl = (Ylâˆ’1, Yl), l = 1, . . . , n, Î¸ij = (Î¾i, Î¾j) âˆˆÎ Ã— Î, i, j = 1, . . . , N. Denote the transformed
alphabet Î˜ = {Î¸ij; i, j = 1, . . . , N} = {ËœÎ¸k; k = 1, . . . , N 2} and note Î˜ = Î Ã— Î with ËœÎ¸1 = Î¸11, . . . , ËœÎ¸N =
Î¸1N, . . . , ËœÎ¸(Nâˆ’1)N+1 = Î¸N1, . . . , ËœÎ¸N2 = Î¸NN. Let also the set of PLs on Î˜ be P(Î˜).
The transformed observations Z = {Zl; l = 1, 2, . . .} form a Markov chain evolving on Î˜; denote its transition
matrix by P = [pij]N2
i, j=1 and the stationary distribution by
Ï€ = (Ï€ij; i, j = 1, . . . , N) = (ËœÏ€k; k = 1, . . . , N 2),
(2)
where Ï€ij denotes the probability of seeing Î¸ij, and ËœÏ€1 = Ï€11, . . . , ËœÏ€N = Ï€1N, . . . , ËœÏ€(Nâˆ’1)N+1 = Ï€N1, . . . , ËœÏ€N 2 =
Ï€NN. We have [7]
p(Î¸ij |Î¸kl ) = 1{i = l}qij,
k, l, i, j = 1, . . . , N,
(3)
which enables us to obtain P directly from Q; see Remark 2 for an example. We can now restate the null hypothesis
H as: the Markov chain Z = {Zl; l = 1, 2, . . .} is drawn from PL Ï€.
To quantify the distance between the empirical PL Î“n and the actual PL Ï€, one considers the relative entropy
(or divergence) between Î“n and Ï€:
D(Î“nâˆ¥Ï€) =
N
X
i=1
N
X
j=1
Î“n(Î¸ij) log Î“n(Î¸ij)/
  PN
t=1 Î“n(Î¸it)

Ï€ij/
  PN
t=1 Ï€it

,
(4)
August 22, 2017
DRAFT
4
and the empirical measure:
Un = âˆšn(Î“n âˆ’Ï€),
(5)
where Ï€ is deï¬ned in (2) and Î“n is the vector
Î“n = (Î“n(Î¸11), . . . , Î“n(Î¸1N), . . . , Î“n(Î¸N1), . . . , Î“n(Î¸NN)).
Let now Hn be the output of a test that decides to accept or to reject the null hypothesis H based on the ï¬rst n
observations in the sequence Z. Under Markovian assumptions (Assumption 1 in Sec. IV), the Hoeffding test [7]
is given by
Hn rejects H if and only if D(Î“nâˆ¥Ï€) > Î·,
(6)
where D(Î“nâˆ¥Ï€) (cf. (4)) is the test statistic and Î· is a threshold.
It is known that the Hoeffding test (6) satisï¬es asymptotic Newman-Pearson optimality [1], [4], in the sense that
it maximizes the exponential decay rate of the misdetection probability over all tests with a false positive probability
with exponential decay rate larger than Î·. Thus, an appropriate threshold Î· should enable the test to have a small
false positive rate while maintaining a satisfactorily high detection rate.
The theoretical false positive rate [5] of the test (6) is given by
Î² = PH(D(Î“nâˆ¥Ï€) > Î·),
(7)
where the subscript H indicates that the probability is taken under the null hypothesis.
Given a tolerable (target) Î², by conducting an ROC analysis for the Hoeffding test using labeled training data,
we could â€œtuneâ€ Î· such that the corresponding discrete test1 [14] has a small false alarm rate and a high detection
rate. In particular, we could select an Î· corresponding to a point close to the northwest corner of the ROC graph.
However, such tuning is too expensive and depends heavily on the quality and quantity of the training data. We can
also, in principle, obtain the corresponding Î· in (7) by directly simulating the samples of the test statistic D(Î“nâˆ¥Ï€),
thus deriving an empirical Cumulative Distribution Function (CDF) and using its (1âˆ’Î²)-quantile. However, we will
note in Remark 5 that this is also computationally too expensive when applied through a so-called â€œwindowingâ€
technique for purposes of anomaly detection. Thus, we seek to estimate Î· without directly simulating the statistic.
To that end, existing work involves using Sanovâ€™s theorem [7] to derive an estimator for Î·. Speciï¬cally, for large
enough n, by replacing the right hand side in (7) by an exponential we can obtain a minimal Î· that sufï¬ces to
bring the false positive rate below Î² [1], [4]. Such an Î· is given by
Î·sv
n,Î² â‰ˆâˆ’(1/n) log(Î²),
(8)
where we use the n, Î² subscript to denote the dependence of this estimator on Î² and n and the label sv indicates
that it is obtained from Sanovâ€™s theorem. We note that the estimator (8) does not contain any direct distributional
information of the statistic D(Î“nâˆ¥Ï€); this might be one of the causes leading to inaccurate estimation of Î·n,Î²,
especially when the sample size n is relatively small in practice. To see this more clearly, one can consider an
1A discrete test corresponds to a ï¬xed speciï¬c value for Î· in (6).
August 22, 2017
DRAFT
5
extreme scenario where N = 4, Î² = 10âˆ’1000, and n = 50 (this is a reasonably small value; comparable to
N 2 = 16). Then by (8), Î·sv
n,Î² would be way bigger than necessary, tending to yield a test with zero false alarm rate
but also zero detection rate for a typical test set. The issue arises because we use an asymptotic large deviations
result for a relatively modest value of n. Our primary goal in this paper is to derive an alternative threshold estimator,
which would hopefully be more accurate than Î·sv
n,Î² for modest values of n, in terms of a certain metric that we
will introduce in Sec. V.
IV. THEORETICAL RESULTS
We introduce the following assumption.
Assumption 1 Z = {Zl; l = 1, 2, . . .} is an aperiodic, irreducible, and positive recurrent Markov chain ([15])
evolving on Î˜ with transition matrix P, stationary distribution Ï€, and with the same Ï€ as its initial distribution.
Remark 1 Since Î˜ is a ï¬nite set, under Assumption 1 Z is uniformly ergodic [15]. Assuming Ï€ as the initial
distribution is done for notational simplicity; our results apply for any feasible initial distribution. Note also that,
under Assumption 1, Ï€ must have full support over Î˜; i.e., each entry in Ï€ is strictly positive.
Lemma 1 Suppose Assumption 1 holds. Then
Ï€ij
PN
t=1 Ï€it
=
Ï€ij
PN
t=1 Ï€ti
= qij,
i, j = 1, . . . , N.
(9)
Proof: See Appendix A.
Remark 2 Under Assumption 1, Remark 1 and Lemma 1 imply that all entries of Q are strictly positive, indicating
that any two states of the original chain Y are connected. This is a stringent condition; yet, in practice, if some
Ï€ij in (9) is zero, we can replace it with a small Îµ > 0, and then normalize the modiï¬ed vector Ï€, thus ensuring
that Assumption 1 is satisï¬ed.
Another reason why we set the zero entries in Ï€ to Îµ > 0 is for convenience of computing the original transition
matrix Q, hence P, via (9) and (3). If we simply eliminate the corresponding states in Z, then it is possible that the
number of the remaining states is not the square of some integer N; this would prevent us from easily recovering
P from Ï€. Consider the following example: Assuming
Q =
ï£®
ï£¯ï£¯ï£¯ï£°
0.1
0.2
0.7
0
0.2
0.8
0.6
0.15
0.25
ï£¹
ï£ºï£ºï£ºï£»,
August 22, 2017
DRAFT
6
then by (3) we have
P =
ï£®
ï£¯ï£¯ï£¯ï£¯ï£¯ï£¯ï£¯ï£¯ï£¯ï£¯ï£¯ï£¯ï£¯ï£¯ï£¯ï£¯ï£¯ï£¯ï£¯ï£¯ï£¯ï£°
0.1
0.2
0.7
0
0
0
0
0
0
0
0
0
0
0.2
0.8
0
0
0
0
0
0
0
0
0
0.6
0.15
0.25
0.1
0.2
0.7
0
0
0
0
0
0
0
0
0
0
0.2
0.8
0
0
0
0
0
0
0
0
0
0.6
0.15
0.25
0.1
0.2
0.7
0
0
0
0
0
0
0
0
0
0
0.2
0.8
0
0
0
0
0
0
0
0
0
0.6
0.15
0.25
ï£¹
ï£ºï£ºï£ºï£ºï£ºï£ºï£ºï£ºï£ºï£ºï£ºï£ºï£ºï£ºï£ºï£ºï£ºï£ºï£ºï£ºï£ºï£»
,
and, by direct calculation, we obtain Ï€ = (0.03, 0.07, 0.23, 0, 0.05, 0.14, 0.3, 0.07, 0.11). Note that only 8 entries
in Ï€ are non-zero and 8 is not the square of some integer N. Thus, if we eliminate the state corresponding to the
zero entry in Ï€, it will be hard to recover Q, hence P.
A. Weak Convergence of Empirical Measure
Let us ï¬rst establish CLT results for one-dimensional empirical measures
Un,k = âˆšn(Î“n(ËœÎ¸k) âˆ’ËœÏ€k),
k = 1, . . . , N 2.
(10)
For k âˆˆ{1, . . . , N 2} deï¬ne
fk(Z) = 1{Z = ËœÎ¸k}.
(11)
Lemma 2 Suppose Assumption 1 holds. Then a Central Limit Theorem (CLT) holds for Un,k; that is, Un,k
d
âˆ’âˆ’âˆ’âˆ’â†’
nâ†’âˆ
N(0, Ïƒ2
k) with Ïƒ2
k = Cov(fk(Z1), fk(Z1)) + 2 Pâˆ
m=1 Cov(fk(Z1), fk(Z1+m)) < âˆ.
Proof: See Appendix B.
Now we state the CLT [16, Thm. 3.1] for the multidimensional empirical measure Un = (Un,k; k = 1, . . . , N 2)
as Lemma 3. Several different proofs for this result are available in [16] and the references therein. For completeness,
we provide a proof that leverages the results from [15], in terms of extending Lemma 2.
Lemma 3 ([16]) Suppose Assumption 1 holds. Then a multidimensional CLT holds for Un; that is,
Un
d
âˆ’âˆ’âˆ’âˆ’â†’
nâ†’âˆN(0, Î›),
(12)
with Î› = [Î›ij]N2
i, j=1 being an N 2 Ã— N 2 covariance matrix given by
Î›ij = ËœÏ€i(Iij âˆ’ËœÏ€j) +
âˆ
X
m=1
[ËœÏ€i(Pm
ij âˆ’ËœÏ€j) + ËœÏ€j(Pm
ji âˆ’ËœÏ€i)],
(13)
where Iij denotes the (i, j)-th entry of the identity matrix, and Pm
ij (resp., Pm
ji) is the (i, j)-th (resp., (j, i)-th)
entry of the matrix Pm (the m-th power of P), i, j = 1, . . . , N 2.
Proof: See Appendix C.
August 22, 2017
DRAFT
7
B. Weak Convergence of Test Statistic
In this section, to derive weak convergence results for the test statistic D(Î½âˆ¥Ï€), we will leverage a method
commonly-used by statisticians in terms of combining a Taylorâ€™s series expansion for the test statistic and the CLT
result for the empirical measure [11]. Recently, under i.i.d. assumptions, such a weak convergence analysis for
certain test statistics has been conducted in [10], [5].
To this end, for Î½ âˆˆP(Î˜) we consider
h(Î½) = D(Î½âˆ¥Ï€) =
N
X
i=1
N
X
j=1
Î½ij log
Î½ij
PN
t=1 Î½it
Ï€ij
PN
t=1 Ï€it
.
(14)
Let U âˆ¼N(0, Î›) with Î› given by (13). Now, we are in a position to derive weak convergence results for our test
statistic D(Î½âˆ¥Ï€).
Theorem 1 Suppose Assumption 1 holds. Then we have the following weak convergence results:
D(Î“nâˆ¥Ï€)
d
âˆ’âˆ’âˆ’âˆ’â†’
nâ†’âˆ
1
2nUâ€²âˆ‡2h(Ï€)U,
(15)
D(Î“nâˆ¥Ï€)
d
âˆ’âˆ’âˆ’âˆ’â†’
nâ†’âˆ
1
2n
N2
X
k=1
ÏkÏ‡2
1k,
(16)
where âˆ‡2h(Ï€) is the Hessian of h(Î½) evaluated at Î½ = Ï€, Ïk, k = 1, . . . , N 2, are the eigenvalues of the matrix
âˆ‡2h(Ï€)Î›, and Ï‡2
1k, k = 1, . . . , N 2, are N 2 independent Ï‡2 random variables with one degree of freedom.
Proof: Let us ï¬rst compute the gradient of h(Î½). Expanding the logarithm and after some algebra which leads
to cancellations of gradient terms with respect to Î½ij in PN
t=1 Î½it, for all i, j = 1, . . . , N, we obtain
âˆ‚h(Î½)
âˆ‚Î½ij
= log Î½ij âˆ’log
 N
X
t=1
Î½it

âˆ’log Ï€ij + log
 N
X
t=1
Ï€it

,
(17)
which implies
âˆ‡h(Ï€) = 0.
(18)
Further, from (17), we compute the Hessian âˆ‡2h(Î½) by
âˆ‚2h(Î½)
âˆ‚Î½ijâˆ‚Î½kl
=
ï£±
ï£´
ï£´
ï£´
ï£´
ï£´
ï£´
ï£²
ï£´
ï£´
ï£´
ï£´
ï£´
ï£´
ï£³
0, if k Ì¸= i,
1
Î½ij
âˆ’
1
PN
t=1 Î½it
, if k = i and l = j,
âˆ’
1
PN
t=1 Î½it
, if k = i and l Ì¸= j.
(19)
Evaluating all the terms in (19) at Î½ = Ï€ yields âˆ‡2h(Ï€), which will play a crucial role in approximating D(Î“nâˆ¥Ï€).
It is seen that âˆ‡2h(Î½) is continuous in a neighborhood of Ï€, and we can utilize the second-order Taylorâ€™s series
expansion of h(Î½) centered at Ï€ to express D(Î“nâˆ¥Ï€) = h(Î“n) âˆ’h(Ï€). Speciï¬cally, by (18) and (5) we have
2nD (Î“n âˆ¥Ï€ ) = 2n (h (Î“n) âˆ’h (Ï€))
= n (Î“n âˆ’Ï€)â€² âˆ‡2h(ËœÎ“n) (Î“n âˆ’Ï€)
= Uâ€²
nâˆ‡2h(ËœÎ“n)Un,
(20)
August 22, 2017
DRAFT
8
where ËœÎ“n = Î¾nÎ“n + (1 âˆ’Î¾n) Ï€ is determined with some Î¾n âˆˆ[0, 1]. From the ergodicity of the chain Z it follows
Î“n
w.p.1
âˆ’âˆ’âˆ’âˆ’â†’
nâ†’âˆÏ€, leading to ËœÎ“n
w.p.1
âˆ’âˆ’âˆ’âˆ’â†’
nâ†’âˆÏ€. By the continuity of âˆ‡2h(Î½) we obtain
âˆ‡2h(ËœÎ“n)
w.p.1
âˆ’âˆ’âˆ’âˆ’â†’
nâ†’âˆâˆ‡2h(Ï€).
(21)
Applying Slutskyâ€™s theorem [17], by (12), (20), and (21) we attain
D(Î“nâˆ¥Ï€) = 1
2nUâ€²
nâˆ‡2h(ËœÎ“n)Un
d
âˆ’âˆ’âˆ’âˆ’â†’
nâ†’âˆ
1
2nUâ€²âˆ‡2h(Ï€)U.
Finally, by means of a linear transformation [18] on the quadratic form Uâ€²âˆ‡2h(Ï€)U, we derive the following
alternative asymptotic result:
D(Î“nâˆ¥Ï€) = 1
2nUâ€²
nâˆ‡2h(ËœÎ“n)Un
d
âˆ’âˆ’âˆ’âˆ’â†’
nâ†’âˆ
1
2n
N2
X
k=1
ÏkÏ‡2
1k,
where Ïk, k = 1, . . . , N 2, are the eigenvalues of the matrix âˆ‡2h(Ï€)Î›, and Ï‡2
1k, k = 1, . . . , N 2, are N 2 independent
Ï‡2 random variables with one degree of freedom.
C. Threshold Approximation
We use an empirical Cumulative Distribution Function (CDF) to approximate the actual CDF of D(Î“nâˆ¥Ï€). In
particular, it is seen from (15) that D(Î“nâˆ¥Ï€) â‰ƒ(1/(2n))Uâ€²âˆ‡2h(Ï€)U for large n. Thus, to derive an empirical
CDF of D(Î“nâˆ¥Ï€), we can generate a set of Gaussian sample vectors independently according to N(0, Î›) and
then plug each such sample vector into the right-hand side of (15) (i.e., replace U), thus, obtaining a set of sample
scalars, as a reliable proxy for samples of D(Î“nâˆ¥Ï€).
Once we obtain an empirical CDF of D(Î“nâˆ¥Ï€), say, denoted Fem(Â·; n), then, by (7), we can estimate Î·n,Î² as
Î·wc
n,Î² â‰ˆF âˆ’1
em (1 âˆ’Î²; n),
(22)
where F âˆ’1
em (Â·; n) is the inverse of Fem(Â·; n). Note that, the Î·wc
n,Î² derived by (22) depends on the entries of the PL Ï€.
In practice, if Ï€ is not directly available, we can replace it by the empirical PL evaluated over a long past sample
path. For such cases, we summarize the procedures of estimating the threshold based on our weak convergence
analysis as Alg. 1, where Ë†Ï€ is a good estimate for Ï€. We note that the length n0 of the past sample path should
be sufï¬ciently large (e.g., n0 â‰¥500N 2) so as to guarantee the validity of taking Ï€ to be Ë†Ï€. In addition, the small
positive number Îµ (e.g., Îµ â‰¤10âˆ’6) introduced in Step 1 is to avoid division by zero, thus ensuring the numerical
stability of the algorithm. If, on the other hand, the actual PL Ï€ is known, then we can still apply Alg. 1 by
replacing the Ë†Ï€ therein with Ï€.
Similar to (22), we can derive another weak convergence based threshold estimator Â¯Î·wc
n,Î² from (16). However, an
easy way of calculating Â¯Î·wc
n,Î² (also summarized in Alg. 1) still cannot avoid simulations; it is hard to conclude any
advantage of Â¯Î·wc
n,Î² over Î·wc
n,Î². As a matter of fact, calculating the eigenvalues of âˆ‡2h(Ï€)Î› makes the calculation
of Â¯Î·wc
n,Î² numerically not as stable, compared to the calculation of Î·wc
n,Î² via Alg. 1. Other methods for numerically
obtaining Â¯Î·wc
n,Î² can be found, e.g., in [19] and the references therein. Another fact we should point out is that, in [20,
p. 30], a slightly different statistic is considered and therefore an even simpler asymptotic distribution can be derived
correspondingly. Moreover, some other papers, e.g., [21], [22], also considered similar but different statistics.
August 22, 2017
DRAFT
9
We will illustrate by extensive experiments that our weak convergence analysis can empirically produce more
accurate estimation of the threshold than Sanovâ€™s theorem for moderate values of n; the price we have to pay,
however, is a relatively long but still acceptable computation time.
Algorithm 1 Threshold estimation for the ordinary Hoeffding test under Markovian assumptions based on weak
convergence analysis.
Input: The sample size n, the target false positive rate Î², the alphabet Î˜ = {ËœÎ¸k; k = 1, . . . , N 2}, a sample path
of the chain Z, denoted Z(0) = {Z
(0)
1 , . . . , Z(0)
n0 }, where n0 is the length, and the Boolean parameter Ï‡2
enab.
1: Estimate ËœÏ€k by
Ë†ËœÏ€k = max
 1
n0
n0
X
i=1
1

Z
(0)
i
= ËœÎ¸k
	
, Îµ

, k = 1, . . . , N 2,
where Îµ > 0 is a small number.
2: Estimate Ï€ as Ë†Ï€ = (Ë†ËœÏ€k/Ë†s; k = 1, . . . , N 2), where Ë†s = PN2
j=1 Ë†ËœÏ€j is a normalizing constant.
3: Estimate âˆ‡2h(Ï€) as âˆ‡2h(Ë†Ï€), by plugging Ë†Ï€ into (19) (i.e., using Ë†Ï€ to replace Î½).
4: Estimate P as Ë†P, via (cf. (3) and Lemma 1)
Ë†p(Î¸ij|Î¸kl) = 1{i = l}Ë†qij,
k, l, i, j = 1, . . . , N,
where Ë†qij = Ë†Ï€ij/(PN
t=1 Ë†Ï€it).
5: Estimate Î› as Ë†Î›, using (by (13) in Lemma 3)
Ë†Î›ij = Ë†ËœÏ€i(Iij âˆ’Ë†ËœÏ€j) +
m0
X
m=1
h
Ë†ËœÏ€i(Ë†Pm
ij âˆ’Ë†ËœÏ€j) + Ë†ËœÏ€j(Ë†Pm
ji âˆ’Ë†ËœÏ€i)
i
,
where m0 is a sufï¬ciently large integer.
6: Update Ë†Î› by setting ( Ë†Î› + Ë†Î›â€²)/2 to Ë†Î›.
7: if Ï‡2
enab = FALSE then
8:
Generate T Gaussian sample vectors Ë†U(t), t = 1, . . . , T, according to N(0, Ë†Î›).
9:
Estimate T samples of D(Î“nâˆ¥Ï€) as (1/(2n)) Ë†U(t)â€²âˆ‡2h(Ë†Ï€) Ë†U(t), t = 1, . . . , T (cf. (15)).
10:
Based on the T samples obtained in the last step, estimate an empirical CDF of D(Î“nâˆ¥Ï€), denoted Fem(Â·; n).
11:
Obtain an estimated value for Î·n,Î² by calculating Î·wc
n,Î² via (22).
12: else if Ï‡2
enab = TRUE then
13:
Calculate the eigenvalues Ë†Ïk, k = 1, . . . , N 2, of the matrix âˆ‡2h(Ë†Ï€) Ë†Î›.
14:
Generate T samples of (1/(2n)) PN 2
k=1 Ë†ÏkÏ‡2
1k (cf. (16)).
15:
Based on the T samples obtained in the last step, estimate an empirical CDF of D(Î“nâˆ¥Ï€), denoted Â¯Fem(Â·; n).
16:
Obtain an estimated value for Î·n,Î² by calculating Â¯Î·wc
n,Î² via (22) with Fem(Â·; n) replaced by Â¯Fem(Â·; n).
17: end if
August 22, 2017
DRAFT
10
Remark 3 In Alg. 1, due to acceptable numerical errors, the originally estimated Ë†Î› (Step 5) could be neither
symmetric nor positive semi-deï¬nite. Symmetry is imposed by Step 6. Further, to ensure positive semi-deï¬niteness
we can diagonalize Ë†Î› as
Ë†Î› = Oâˆ’1diag(Î»1, . . . , Î»N2)O,
(23)
where O is an orthogonal matrix and diag(Î») a diagonal matrix with the elements of Î» in the main diagonal. Due
to numerical errors we might encounter cases where some Î»i are either negative or too small; we can replace them
with small positive numbers and recalculate the right-hand side of (23), thus obtaining an updated positive-deï¬nite
Ë†Î›. For implementation details, the reader is referred to [23].
D. A Robust Hoeffding Test
Many actual systems exhibit time-varying behavior. In this section, we extend our methodology to accommodate
such systems and use a set of PLs (instead of a single PL Ï€) to model past system activity.
Let the null hypothesis H be deï¬ned as: Z = {Zl; l = 1, 2, . . .} is drawn according to the set of PLs Î  =
{Ï€(1), . . . , Ï€(L)} âŠ‚P(Î˜), i.e., Z is drawn from one of the PLs in Î  but we do not know from which one.
Consider a robust version of the Hoeffding test [4], [5], [24] under Markovian assumptions:
Hn rejects H if and only if
inf
Ï€âˆˆÎ  D(Î“nâˆ¥Ï€) > Î·.
(24)
Essentially, the test selects the most likely PL from Î  and uses that to make a decision as in (6). Asymptotic
Newman-Pearson optimality of this test is shown in [4].
For l = 1, . . . , L, let P(l) denote the transition matrix corresponding to Ï€(l) and, similar to (2), we write
Ï€
(l) = (Ï€
(l)
ij ; i, j = 1, . . . , N) = (ËœÏ€
(l)
k ; k = 1, . . . , N 2).
Assume Z is drawn from PL Ï€(l) which satisï¬es Assumption 1. Let U(l)
n = âˆšn(Î“n âˆ’Ï€(l)). By Lemma 3, we have
U
(l)
n
d
âˆ’âˆ’âˆ’âˆ’â†’
nâ†’âˆN(0, Î›
(l)),
(25)
where Î›(l) =

Î›
(l)
ij
N2
i, j=1 is given by
Î›
(l)
ij
= ËœÏ€
(l)
i (Iij âˆ’ËœÏ€
(l)
j )
+
âˆ
X
m=1
[ËœÏ€
(l)
i (P
(l)m
ij
âˆ’ËœÏ€
(l)
j ) + ËœÏ€
(l)
j (P
(l)m
ji
âˆ’ËœÏ€
(l)
i )],
with P
(l)m
ij
being the (i, j)-th entry of the matrix P(l)m (the m-th power of P(l)). Let U(l) âˆ¼N(0, Î›(l)). Using
(15) we obtain
D(Î“nâˆ¥Ï€
(l)) â‰ƒ1
2nU
(l)â€²âˆ‡2h(Ï€
(l))U
(l),
which leads to an approximation for the inï¬mum term in (24):
inf
Ï€âˆˆÎ  D(Î“nâˆ¥Ï€) â‰ƒ
inf
lâˆˆ{1,...,L}
1
2nU
(l)â€²âˆ‡2h(Ï€
(l))U
(l).
(26)
August 22, 2017
DRAFT
11
By the right-hand side of (26), we can generate Gaussian samples to compute a reliable proxy for the samples of
infÏ€âˆˆÎ  D(Î“nâˆ¥Ï€), thereby, obtaining an empirical CDF, denoted F rob
em (Â·; n), of infÏ€âˆˆÎ  D(Î“nâˆ¥Ï€). Thus, given a
target false positive rate Î², similar to (22), we can estimate the threshold Î·n,Î² as
Î·wc
n,Î² â‰ˆ(F rob
em )âˆ’1(1 âˆ’Î²; n),
(27)
where (F rob
em )âˆ’1(Â·; n) denotes the inverse of F rob
em (Â·; n). Similar to (16), we can also derive a Ï‡2-type asymptotic
approximation to the distribution of infÏ€âˆˆÎ  D(Î“nâˆ¥Ï€), thus obtaining another WC-based threshold estimator Â¯Î·wc
n,Î²;
for economy of space, we omit the details. For the cases where the PLs are not directly available, we summarize
the calculation of Î·wc
n,Î² for the robust Hoeffding test as Alg. 2.
Algorithm 2 Threshold estimation for the robust Hoeffding test under Markovian assumptions based on weak
convergence analysis.
Input: The sample size n, the target false positive rate Î², the alphabet Î˜ = {ËœÎ¸k; k = 1, . . . , N 2}, and a sample
path of each PL Ï€(l), denoted Z(l0) = {Z
(l0)
1
, . . . , Z(l0)
n0 }, where n0 is the length, l = 1, . . . , L.
1: for l = 1, . . . , L do
2:
Estimate ËœÏ€
(l)
k , k = 1, . . . , N 2, by
Ë†ËœÏ€
(l)
k = max
 1
n0
n0
X
i=1
1{Z
(l0)
i
= ËœÎ¸k}, Îµ

,
where Îµ > 0 is a small number.
3:
Estimate Ï€(l) as Ë†Ï€(l) = (Ë†ËœÏ€
(l)
k /Ë†s(l); k = 1, . . . , N 2), where Ë†s(l) = PN2
j=1 Ë†ËœÏ€
(l)
j
is normalizing constant.
4:
Estimate âˆ‡2h(Ï€(l)) as âˆ‡2h(Ë†Ï€(l)), by plugging Ë†Ï€(l) into (19) (i.e., using Ë†Ï€(l) to replace Î½).
5:
Estimate P(l) as Ë†P(l), via (cf. (3) and Lemma 1)
Ë†p
(l)(Î¸ij|Î¸kl) = 1{i = l}Ë†q
(l)
ij ,
k, l, i, j = 1, . . . , N,
where Ë†q
(l)
ij = Ë†Ï€
(l)
ij /(PN
t=1 Ë†Ï€
(l)
it ).
6:
Estimate Î›(l) as Ë†Î›(l), using (by (13) in Lemma 3)
Ë†Î›
(l)
ij =Ë†ËœÏ€
(l)
i (Iij âˆ’Ë†ËœÏ€
(l)
j ) +
m0
X
m=1
h
Ë†ËœÏ€
(l)
i (Ë†P
(l)m
ij
âˆ’Ë†ËœÏ€
(l)
j )
+ Ë†ËœÏ€
(l)
j (Ë†P
(l)m
ji
âˆ’Ë†ËœÏ€
(l)
i )
i
,
where m0 is a sufï¬ciently large integer.
7:
Update Ë†Î›(l) by setting ( Ë†Î›(l) + Ë†Î›(l)â€²)/2 to Ë†Î›(l).
8:
Generate T Gaussian sample vectors Ë†U(lt), t = 1, . . . , T, according to N(0, Ë†Î›(l)).
9: end for
10: Estimate T samples of infÏ€âˆˆÎ  D(Î“nâˆ¥Ï€) as inflâˆˆ{1,...,L}(1/2n) Ë†U(lt)â€²âˆ‡2h(Ï€(l)) Ë†U(lt), t = 1, . . . , T (cf. (26)).
11: Based on the T samples obtained in the last step, estimate an empirical CDF of infÏ€âˆˆÎ  D(Î“nâˆ¥Ï€), denoted
F rob
em (Â·; n).
12: Obtain an estimated value for Î·n,Î² by calculating Î·wc
n,Î² via (27).
August 22, 2017
DRAFT
12
10
15
20
25
n (sample size)
0.0
0.5
1.0
1.5
Î· (threshold)
Î·âˆ—
n, Î²(N)
Î·wc
n, Î²(N)
Â¯Î·wc
n, Î²(N)
Î·sv
n, Î²(N)
(a) N = 2.
30
40
50
60
70
80
90
100
n (sample size)
0.0
0.2
0.4
0.6
0.8
Î· (threshold)
Î·âˆ—
n, Î²(N)
Î·wc
n, Î²(N)
Â¯Î·wc
n, Î²(N)
Î·sv
n, Î²(N)
(b) N = 4.
80
100
120
140
160
180
200
220
n (sample size)
0.0
0.1
0.2
0.3
0.4
0.5
0.6
Î· (threshold)
Î·âˆ—
n, Î²(N)
Î·wc
n, Î²(N)
Â¯Î·wc
n, Î²(N)
Î·sv
n, Î²(N)
(c) N = 6.
150
200
250
300
350
n (sample size)
0.0
0.1
0.2
0.3
0.4
0.5
Î· (threshold)
Î·âˆ—
n, Î²(N)
Î·wc
n, Î²(N)
Â¯Î·wc
n, Î²(N)
Î·sv
n, Î²(N)
(d) N = 8.
Fig. 1: Threshold versus sample size; scenarios corresponding to Î² = 0.001, N = 2, 4, 6, 8.
V. EXPERIMENTAL RESULTS
In this section, we assess the accuracy of our threshold estimator and the performance of the anomaly detection
procedure. We start with a numerical evaluation of the thresholdâ€™s accuracy and then perform anomaly detection in
two application settings using simulated and actual data.
A. Numerical Results for Threshold Approximation
In this subsection, for simplicity we consider the ordinary (and not the robust) Hoeffding test. We have developed
a software package TAM [23] to perform the experiments. We will use Î˜ = {1, 2, . . . , N 2} to indicate the states
and assume the stationary distribution Ï€ to also be the initial distribution.
In the following numerical examples, we ï¬rst randomly create a valid (i.e., such that Assumption 1 holds) N Ã—N
transition matrix Q, giving rise to an N 2 Ã— N 2 transition matrix P, and then generate T test sample paths of the
chain Z, each with length n, denoted Z(t) = {Z
(t)
1 , . . . , Z(t)
n }, t = 1, . . . , T. We use these samples to derive empirical
CDFâ€™s. To simulate the case where the PL Ï€ is not directly available, we generate one more independent reference
sample path Z(0) = {Z
(0)
1 , . . . , Z(0)
n0 } of length n0 â‰«|Î˜| = N 2, thus enabling us to obtain a good estimate of Ï€.
Note that we do not rely on the test sample paths to estimate the PL Ï€. The ground truth Ï€ is computed by taking
any row of Pm0 for some sufï¬ciently large m0.
Having the ground truth PL Ï€ at hand, with the test sample paths Z(t) = {Z
(t)
1 , . . . , Z(t)
n }, t = 1, . . . , T, we can
compute T samples of the scalar random variable D(Î“nâˆ¥Ï€), by (4). Using these samples, we obtain an empirical
CDF of D(Î“nâˆ¥Ï€), denoted F(Â·; n), which can be treated as a dependable proxy of the actual one. The threshold
given by (22) with Fem(Â·; n) replaced by F(Â·; n) is then taken as a reliable proxy of Î·n,Î². We denote this proxy
by Î·âˆ—
n,Î². To emphasize the dependence on N, we write Î·n,Î² (resp., Î·âˆ—
n,Î²) as Î·n,Î²(N) (resp., Î·âˆ—
n,Î²(N)). Next, using
the reference sample path Z(0) and applying Alg. 1, we obtain Î·wc
n,Î²(N) and Â¯Î·wc
n,Î²(N).
Let the target false positive rate be Î² = 0.001. Consider four different scenarios where N is 2, 4, 6, and 8,
respectively. Set Îµ = 10âˆ’10, T = 1000, m0 = 1000, and n0 = 1000N 2. Here we note that, in all our experiments,
August 22, 2017
DRAFT
13
an estimate Ë†Ï€ for Ï€ with âˆ¥Ë†Ï€ âˆ’Ï€âˆ¥â‰¤10âˆ’6 can be obtained by executing Alg. 1 with parameters n0 â‰¥500N 2 and
Îµ â‰¤10âˆ’8. In Figs. 1a through 1d, the red line plots Î·âˆ—
n,Î²(N), the blue line Î·wc
n,Î²(N), the magenta line Â¯Î·wc
n,Î²(N),
and the green line Î·sv
n,Î²(N) (cf. (8)), all as a function of the sample size n. Setting sample sizes n reasonably small
(n should at least be comparable to N 2), it can be seen that Î·wc
n,Î²(N) and Â¯Î·wc
n,Î²(N) are more accurate than Î·sv
n,Î²,
except for the case N = 2 where all estimators perform approximately equally well. In particular, as N increases,
the estimation errors of Î·wc
n,Î²(N) and Â¯Î·wc
n,Î²(N) are consistently close to zero, while the approximation error of Î·sv
n,Î²
increases signiï¬cantly. Moreover, for the scenarios N = 6, 8, Î·wc
n,Î²(N) and Â¯Î·wc
n,Î²(N) are very close.
10
15
20
25
n
0.0
0.2
0.4
0.6
0.8
d(Ë†Î·, Î·âˆ—; n, Î², N, K)
Î² = 0. 001, N = 2, K = 200
Ë†Î· = Î·sv
Ë†Î· = Î·wc
Ë†Î· = Â¯Î·wc
(a)
30
40
50
60
70
80
90
100
n
0.00
0.02
0.04
0.06
0.08
d(Ë†Î·, Î·âˆ—; n, Î², N, K)
Î² = 0. 001, N = 4, K = 200
Ë†Î· = Î·sv
Ë†Î· = Î·wc
Ë†Î· = Â¯Î·wc
(b)
80
100
120
140
160
180
200
220
n
0.00
0.02
0.04
0.06
0.08
0.10
d(Ë†Î·, Î·âˆ—; n, Î², N, K)
Î² = 0. 001, N = 6, K = 200
Ë†Î· = Î·sv
Ë†Î· = Î·wc
Ë†Î· = Â¯Î·wc
(c)
150
200
250
300
350
n
0.00
0.02
0.04
0.06
0.08
0.10
d(Ë†Î·, Î·âˆ—; n, Î², N, K)
Î² = 0. 001, N = 8, K = 200
Ë†Î· = Î·sv
Ë†Î· = Î·wc
Ë†Î· = Â¯Î·wc
(d)
Fig. 2: Evaluation of average squared estimation errors for different types of threshold estimators.
Remark 4 In Figs. 1a-1d, the red line representing the â€œactualâ€ value Î·âˆ—
n,Î² is not smooth; this is because each time
when varying the sample size n, we regenerate all the sample paths Z(t) = {Z
(t)
1 , . . . , Z(t)
n }, t = 1, . . . , T from
scratch. On the other hand, the blue (resp., magenta) line corresponding to Î·wc
n,Î² (resp., Â¯Î·wc
n,Î²) is smooth because we
only need to generate the T Gaussian (resp., Ï‡2-type) sample vectors once. In our experiments, most of the running
time is spent generating the sample paths Z(t) and calculating Î·âˆ—
n,Î² therefrom. In practice, we will neither generate
such samples nor calculate Î·âˆ—
n,Î², and only need to focus on obtaining Î·wc
n,Î² or Â¯Î·wc
n,Î², which is computationally not
expensive.
Remark 5 Theoretically speaking, we could use the â€œactualâ€ threshold Î·âˆ—
n,Î² as obtained above, but it is of little
practical value; the reason is that in statistical anomaly detection applications, we are typically faced with a long
series of observations and want to use a so-called windowing technique (see Sec. V-C), which divides the observations
into a sequence of detection windows with the same time length. The sample sizes n in different windows may
not necessarily be equal, leading to different threshold settings when sliding the windows. If we use the simulated
â€œactualâ€ threshold, then, when varying the detection windows, we will need to regenerate the corresponding samples
(for threshold estimation purposes) from scratch, which is computationally too expensive, especially when there are
many detection windows. In contrast, to compute our estimator Î·wc
n,Î² (resp., Â¯Î·wc
n,Î²), we only need to generate one
August 22, 2017
DRAFT
14
set of Gaussian (resp., Ï‡2-type) sample vectors (cf. Remark 4), which can be shared by all the detection windows,
thus, saving a lot of computation time. To see this more clearly, let us denote by Ï„1 the average running time for
generating a set of samples with T (T = 1000 is empirically a good choice) Gaussian (resp., Ï‡2-type) vectors
according to (15) (resp., (16)), and Ï„2 the average running time for calculating a threshold via (22) given the
corresponding sample vectors required to derive the empirical CDF. Clearly, we have Ï„1 â‰«Ï„2 > 0. Assume we
have W detection windows. Then, if we directly simulate the statistic so as to estimate the threshold for each and
every detection window, the total running time would be c1WÏ„1 + c2WÏ„2 = (c1Ï„1 + c2Ï„2)W, where c1, c2 > 0 are
two scaling constants satisfying c1Ï„1 â‰«c2Ï„2. On the other hand, by simulating Gaussian (resp., Ï‡2-type) samples,
the total running time required to estimate all the thresholds for the W detection windows would be c3Ï„1 +c4Ï„2W,
where c3, c4 > 0 are two scaling constants satisfying c4 â‰ˆc2, leading to 0 < c4Ï„2 â‰ªc1Ï„1 + c2Ï„2. Thus, for large
W we have c3Ï„1 + c4Ï„2W â‰ª(c1Ï„1 + c2Ï„2)W.
To further investigate the performance of different classes of threshold estimators, we now take the randomness
of the transition matrix P into account and deï¬ne a simulation-based metric d (Ë†Î·, Î·âˆ—; n, Î², N, K) to quantify the
average squared empirical estimation error, speciï¬ed as follows:
d (Ë†Î·, Î·âˆ—; n, Î², N, K) = 1
K
K
X
k=1

Ë†Î·
(k)
n,Î² (N) âˆ’Î·
âˆ—(k)
n,Î² (N)
2
.
(28)
Recall that N is a parameter representing the number of states in the original chain Y. We denote by Ë†Î· the
threshold estimator class (could be Î·sv, Î·wc, or Â¯Î·wc), and by Î·âˆ—a proxy of the actual threshold class (derived by
directly simulating the samples of the test statistic). Denote by K the number of independent repetitions of the
calculation for (Ë†Î·
(k)
n,Î²(N) âˆ’Î·
âˆ—(k)
n,Î² (N))2, where Ë†Î·
(k)
n,Î²(N) (resp., Î·
âˆ—(k)
n,Î² (N)) denotes the class Ë†Î· (resp., Î·âˆ—) instantiated
under parameters n, Î², N, and k âˆˆ{1, . . . , K}.
Setting Î² = 0.001, K = 200, N âˆˆ{2, 4, 6, 8}, and n âˆˆ

Â¯n = 2N 2 + i Ã—

0.2N 2 + 1

: Â¯n < 6N 2 + 5, i âˆˆN+
	
,
we evaluate d (Ë†Î·, Î·âˆ—; n, Î², N, K). The results are shown in Fig. 2. Several observations can be made from Figs.
2a-2d: (i) Except for the case N = 2, both Î·wc and Â¯Î·wc outperform Î·sv, that is, d (Î·wc, Î·âˆ—; n, Î², N, K) <
d (Î·sv, Î·âˆ—; n, Î², N, K) and d (Â¯Î·wc, Î·âˆ—; n, Î², N, K) < d (Î·sv, Î·âˆ—; n, Î², N, K). (ii) For the cases N = 6, 8, Î·wc and Â¯Î·wc
perform almost equally well, with both d (Î·wc, Î·âˆ—; n, Î², N, K) and d (Â¯Î·wc, Î·âˆ—; n, Î², N, K) being very close to zero
and, for the cases N = 2, 4, Î·wc outperforms Â¯Î·wc, i.e., d (Î·wc, Î·âˆ—; n, Î², N, K) < d (Â¯Î·wc, Î·âˆ—; n, Î², N, K). (iii) Only
for the case N = 2, Î·sv performs the best among the three estimators and, Î·wc performs approximately equally
well with Î·sv in this case. More extensive comparison results can be derived using TAM [23]. We may empirically
conclude that, Î·wc performs consistently the best among the three for almost all scenarios that we have considered
and, on the other hand, Î·sv performs unsatisfactorily when N > 2, and Â¯Î·wc is numerically not as stable as Î·wc,
especially for the cases where N â‰¤4.
B. ROC Analysis for the Hoeffding Test with Different Threshold Estimators
In this subsection, for simplicity and economy of space, we again only consider the ordinary (and not the robust)
Hoeffding test. We note here that similar results can be derived for the robust Hoeffding test. The numerical
experiments are conducted using the software package ROM [25].
August 22, 2017
DRAFT
15
0.0
0.2
0.4
0.6
0.8
1.0
FPR
0.0
0.2
0.4
0.6
0.8
1.0
TPR
N = 4, n = 50
HTSV
HTWC-1
HTWC-2
(a)
0.0
0.2
0.4
0.6
0.8
1.0
FPR
0.0
0.2
0.4
0.6
0.8
1.0
TPR
N = 6, n = 100
HTSV
HTWC-1
HTWC-2
(b)
Fig. 3: Results from ROC analysis of the ordinary Hoeffding test.
TABLE I: ROC points vs. target FPR (N = 4, n = 50).
target FPR Î²
HTWC-1
HTWC-2
HTSV
FPR
TPR
FPR
TPR
FPR
TPR
0.001
0.002
0.885
0.0
0.816
0.402
0.999
0.01
0.011
0.965
0.002
0.888
0.752
1.0
0.02
0.018
0.983
0.003
0.943
0.844
1.0
0.03
0.025
0.99
0.01
0.96
0.898
1.0
0.04
0.038
0.99
0.018
0.971
0.927
1.0
0.05
0.047
0.991
0.029
0.981
0.945
1.0
Let Î˜ = {1, 2, . . . , N 2} containing N 2 states. For a given sample size n and a given target false positive rate
(FPR) Î², the three thresholds Î·wc
n,Î², Â¯Î·wc
n,Î², and Î·sv
n,Î², respectively, give rise to three different discrete tests (denote
them by â€œHTWC-1,â€ â€œHTWC-2,â€ and â€œHTSV,â€ respectively). To compare their performances, we will conduct the
Receiver Operating Characteristic (ROC) [14] analysis (detection rate vs. false alarm rate) using simulated data.
Similar to what we have done in Sec. V-A, we ï¬rst randomly create a valid N Ã— N transition matrix Q, hence
an N 2 Ã— N 2 transition matrix P, and then generate T sample paths of the chain Z, each with length n, denoted
Z(t) = {Z
(t)
1 , . . . , Z(t)
n }, t = 1, . . . , T. From P we derive the PL Ï€. Next, to simulate anomalies, we create another
valid N Ã— N transition matrix Â¯Q, hence an N 2 Ã— N 2 transition matrix Â¯P, and generate T sample paths of the
corresponding chain Â¯Z, each with length n, denoted Â¯Z(t) = { Â¯Z
(t)
1 , . . . , Â¯Z(t)
n }, t = 1, . . . , T. Label each sample path of
TABLE II: ROC points vs. target FPR (N = 6, n = 100).
target FPR Î²
HTWC-1
HTWC-2
HTSV
FPR
TPR
FPR
TPR
FPR
TPR
0.001
0.001
1.0
0.0
1.0
0.997
1.0
0.01
0.008
1.0
0.003
1.0
1.0
1.0
0.02
0.017
1.0
0.005
1.0
1.0
1.0
0.03
0.028
1.0
0.017
1.0
1.0
1.0
0.04
0.037
1.0
0.017
1.0
1.0
1.0
0.05
0.055
1.0
0.019
1.0
1.0
1.0
August 22, 2017
DRAFT
16
Â¯Z (resp., Z) with length n as â€œpositiveâ€ (resp., â€œnegativeâ€). Then, {Z(t) : t âˆˆ{1, . . . , T}}âˆª{Â¯Z(t) : t âˆˆ{1, . . . , T}}
will be our test set, which contains T negative (Z(t)) and T positive (Â¯Z(t)) sample paths.
Now, by executing Alg. 1 without estimating Ï€ (since the ground truth is available), we obtain Î·wc
n,Î² and Â¯Î·wc
n,Î².
Also, by (8) we obtain Î·sv
n,Î². For each sample path in the test set, we compute D(Î“nâˆ¥Ï€) by (4). Next, using
Î·wc
n,Î² (resp., Â¯Î·wc
n,Î², Î·sv
n,Î²), we can apply HTWC-1 (resp., HTWC-2, HTSV) to detect each sample path as positive
or negative. Then, we integrate these reports with the ground truth labels so as to calculate the true positive rate
(TPR) and FPR, thereby, obtaining a point of the ROC space.
In our experiments, we take T = 1000. Fig. 3a (resp., 3b) shows the ROC graphs of HTWC-1, HTWC-2, and
HTSV for a scenario corresponding to N = 4, n = 50 (resp., N = 6, n = 100); different points on the graph are
obtained by Î² taking values from a predesignated ï¬nite set {0.001} âˆª{0.01, 0.02, . . . , 0.19}. It is seen from Fig.
3a (or Fig. 3b) that all TPR values are very close to 1, which is good, but for most cases (each case corresponds
to a speciï¬c â€œsmallâ€ target FPR Î²) HTWC-1 and HTWC-2 have much closer FPR values to the target FPR value
than HTSV, meaning HTWC-1 and HTWC-2 are able to control for false alarms better than HTSV. To see this
more clearly, we show a few speciï¬c values of the (TPR, FPR) pair in Tables I and II. It is worth noting that in the
N = 6 scenario, HTSV is almost a random guess for all the target FPR cases that are considered. More extensive
experiments show that, as N increases, the performance of HTSV gets worse and worse; in particular, when N â‰¥6,
HTSV is very likely merely a random guess yielding an ROC point close to (1, 1). During our experiments, another
observation is that, for each ï¬xed N and Î², when n increases, all HTWC-1, HTWC-2, and HTSV perform better
and better; this is because with larger sample sizes, all the three estimators Î·wc
n,Î², Â¯Î·wc
n,Î², and Î·sv
n,Î² approximate the
actual Î·n,Î² better. We therefore conclude that HTWC-1 (or HTWC-2) typically outperforms HTSV in the sense
that the former has a better capability of controlling the false alarm rate (i.e., FPR) while maintaining a satisfactory
detection rate (i.e., TPR).
Remark 6 A natural concern about the ROC analysis above might be the setting of the target FPR (Î²) values;
one may ask: How about always setting Î² to a â€œvery smallâ€ value, say, 10âˆ’10, 10âˆ’100, or even 10âˆ’1000? We have
actually already discussed this partly in Sec. III. Setting a too small Î² would typically lead to an unsatisfactory
detection rate (TPR). In addition, note that Î·wc
n,Î² (or Â¯Î·wc
n,Î²) is numerically obtained from an empirical CDF, say, G(x),
of some scalar random variable; we have G(x) nondecreasing, and limxâ†’+âˆG (x) = 1, implying that ï¬nding an
â€œaccurateâ€ x such that G(x) = 1 âˆ’Î² would be hard for a too small Î² âˆˆ(0, 1). An empirically â€œgoodâ€ choice of Î²
is 0.001 (see Tabs. I and II), which is what we use in our applications. Because HTWC-1 and HTWC-2 perform
almost equally well in our experiments, but HTWC-1 is more stable and less computationally demanding, we will
only apply HTWC-1 in the following.
C. Simulation Results for Network Anomaly Detection
In this subsection we test our approach in a communication network trafï¬c anomaly detection application. We
will use the term trafï¬c and ï¬‚ow interchangeably. We perform the simulations using the software package SADIT
August 22, 2017
DRAFT
17
Fig. 4: Simulation setting (from [4]).
0
1000
2000
3000
4000
5000
6000
7000
time (s)
0.00
0.05
0.10
0.15
0.20
0.25
0.30
divergence
(a) Sanov
0
1000
2000
3000
4000
5000
6000
7000
time (s)
0.00
0.05
0.10
0.15
0.20
0.25
0.30
divergence
(b) WC
Fig. 5: Detection results for Scenario V-C-1 with wd = 50 s, ws = 200 s, k = 2, n1 = 1, n2 = 2, n3 = 2; (a)
threshold is estimated by use of Sanovâ€™s theorem; (b) threshold is estimated by use of the weak convergence result.
[8], which, based on the fs-simulator [26], is capable of efï¬ciently generating ï¬‚ow-level network trafï¬c datasets
with annotated anomalies.
As shown in Fig. 4, the simulated network consists of an internal network involving eight normal users (CT1-
CT8), a server (SRV) that stores sensitive information, and three Internet nodes (INT1-INT3) that connect to the
internal network via a gateway (GATEWAY).
As in [4, Sec. III.A], to characterize the statistical properties of the ï¬‚ow data, we use as features the ï¬‚ow duration
and size (bits). We also cluster the source/destination IP addresses and use as features for each ï¬‚ow the assigned
cluster ID and the distance of the ï¬‚owâ€™s IP from the cluster center. For each feature, we quantize its values into
discrete symbols so as to obtain a ï¬nite alphabet Î, hence Î˜, for our model. Based on the time stamps (the start
times) of the ï¬‚ows, we divide the ï¬‚ow data into a series of detection windows, each of which contains a set of
ï¬‚ow observations (see [4] for details).
To implement our anomaly detection approach, we ï¬rst estimate a PL Ï€ (resp., a PL set Î ) from the stationary
(resp., time-varying) normal trafï¬c. Note that, for either case, the reference data should be anomaly-free ideally.
However, in our experiments, for the stationary case we use as reference trafï¬c the entire ï¬‚ow sequence with
anomalies injected at some time interval; this makes sense because the size of a typical detection window is much
smaller than that of the whole ï¬‚ow sequence and the fraction of anomalies is indeed very small, leading to an
estimation for the PL with acceptable accuracy. On the other hand, for the time-varying case we generate the
reference trafï¬c without anomalies and the test trafï¬c with anomalies separately, sharing all the parameter settings
in the statistical model used in SADIT except the ones for introducing anomalies. Note that, estimating a PL for
August 22, 2017
DRAFT
18
the stationary trafï¬c is relatively easy, while, for the time-varying trafï¬c, we need to make an effort to estimate
several different PLs corresponding to certain periods of the day. We apply the two-step procedure proposed in [4];
that is, we ï¬rst generate a relatively large PL set and then reï¬ne the candidate PLs therein by solving a weighted
set cover problem. Note also that, if we already know the periodic system activity pattern, then we can directly
estimate the PL set period by period; see another anomaly detection application in Sec. V-D for example.
Now, having the reference PL (resp., PL set) at hand, we persistently monitor the test trafï¬c and report an
anomaly instantly as long as the relative entropy D(Î“nâˆ¥Ï€) (resp., infÏ€âˆˆÎ  D(Î“nâˆ¥Ï€)) exceeds the threshold Î·wc
n,Î²
for the current detection window, where n is the number of ï¬‚ow samples within the window. It is worth pointing
out that, for the current application, we will not seek to identify which ï¬‚ows belonging to an abnormal detection
window contribute mostly to causing the anomaly, but, in some other applications, e.g., the one in Sec. V-D, we
will do so.
In the following, we consider two scenarios â€“ one for stationary trafï¬c and the other for time-varying trafï¬c.
1) Stationary Network Trafï¬c â€“ Scenario V-C-1: We mimic anomalies caused by a large ï¬le download [3, Sec.
IV.A.2]. The simulation time is 7000 s. A user increases its mean ï¬‚ow size to 10 times the usual value between
1000 s and 1500 s. The interval between the starting points of two consecutive time windows is taken as wd = 50
s, the window-size is set to ws = 200 s, and the target false positive rate is set to Î² = 0.001. The number of user
clusters is k = 2 and the quantization level for ï¬‚ow duration, ï¬‚ow size, and distance to cluster center is set to
n1 = 1, n2 = 2, and n3 = 2, respectively. Thus, the original chain has N = 2 Ã— 1 Ã— 2 Ã— 2 = 8 states, and we have
N 2 = 64 states in the transformed chain.
The detection results are shown in Figs. 5a and 5b, both of which depict the relative entropy (divergence) metric
deï¬ned in (4). The green dashed line in Fig. 5a is the threshold estimated using Sanovâ€™s theorem (i.e., Î·sv
n,Î² given
by (8), where n is the sample size in each speciï¬c detection window). The green dashed line in Fig. 5b is the
threshold given by our estimator (i.e., Î·wc
n,Î² computed by Alg. 1). The interval during which the divergence curve is
above the threshold line (the red segment) corresponds to the time instances reported as abnormal. Fig. 5a shows
that, if Î·sv
n,Î² is used as the threshold, then the Hoeffding test reports too many false alarms, and, Fig. 5b shows that,
if, instead, we use Î·wc
n,Î² as the threshold, then the Hoeffding test does not report any false alarm while successfully
identifying the true anomalies between 1000 s and 1500 s.
2) Time-Varying Network Trafï¬c â€“ Scenario V-C-2: Consider the case where the network in Fig. 4 is simulated
with a day-night trafï¬c pattern in which the ï¬‚ow size follows a log-normal distribution. We use precisely the same
scenario as that in [4, Sec. IV.B.2]. The ground truth anomaly (consider an anomaly where node CT2 increases its
mean ï¬‚ow size by 30%) is injected beginning at 59 h and lasting for 80 minutes.
Using the two-step procedure proposed in [4, Sec. III.C], we ï¬rst obtain 32 rough PL candidates. Then, using the
PL reï¬nement algorithm given in [4, Sec. III.D] equipped with the cross-entropy threshold parameter Î» = 0.028,
which is determined by applying Alg. 2, we ï¬nally obtain 6 PLs, being active during morning, afternoon, evening,
mid-night, dawn, and the transition time around sunrise, respectively. Note that, since we have obtained the PL set
in a different way, in the following, when applying Alg. 2 for each detection window, we can skip the ï¬rst two
steps (lines 2 and 3). In the subsequent detection procedure, the chief difference between our method and the one
August 22, 2017
DRAFT
19
0
20
40
60
80
100
120
140
160
time (h)
0.00
0.02
0.04
0.06
0.08
0.10
0.12
0.14
0.16
divergence
Fig. 6: Detection result for Scenario V-C-2 with wd = 1000 s, ws = 1000 s, k = 1, n1 = 1, n2 = 4, n3 = 1.
used in [4] is that we no longer set the threshold universally as a constant; instead, we calculate the threshold Î·wc
n,Î²
for each detection window using Alg. 2. Set k = 1, n1 = 1, n2 = 4, and n3 = 1. Thus, the original chain has
N = 1 Ã— 1 Ã— 4 Ã— 1 = 4 states, and we have N 2 = 16 states in the transformed chain for this case. Take wd = 1000
s, ws = 1000 s, and Î² = 0.001. We see from Fig. 6 that the anomaly is successfully detected, without any false
alarms.
D. Anomaly Detection for Waze Jams
1) Dataset Description: The Waze datasets under investigation are kindly provided to us by the Department of
Innovation and Technology (DoIT) in the City of Boston. The datasets include three parts: the jam data J1 (trafï¬c
slowdown information generated by Waze based on usersâ€™ location and speed; note that each jam consists of a set
of points), the corresponding point data J2 (latitudes and longitudes of the points within jams), and the alert data
J3 (trafï¬c incidents reported by active users; we will call such a user a â€œWazerâ€). For each part, we only list the
features that we have used in our algorithms. In particular, each entry (jam) in J1 has the following ï¬elds: uuid
(unique jam ID), start time, end time, speed (current average speed on jammed segments in meters per second),
delay (delay caused by the jam compared to free ï¬‚ow speed, in seconds), and length (jam length in meters). The
information for each entry in J2 includes a jam uuid and the locations (latitudes and longitudes) of the points
within the jam. The ï¬elds of each entry in J3 include: uuid (unique system ID; this is different from the jam ID
in J1), location (latitude and longitude per report), type (event type; e.g., accident, weather hazard, road closed,
etc.), start time, and end time. It is seen that, by combing J1 and J2, we can denote each jam in J1 as
(i, uuid[i], loc[i], speed[i], delay[i], length[i], startTime[i]),
where i is the index, uuid is the unique jam ID, â€œlocâ€ (resp., â€œstartTimeâ€) is the abbreviation for location (resp.,
start time). Because we are only interested in detecting the abnormal jams in real-time, we will not use the jam
end times.
2) Anomaly Description: Typically we can observe lots of jams in certain areas during rush hour, e.g., the
AM/PM peaks, and most of them are â€œnormalâ€ except those with extremely atypical features (delay, length, etc.).
On the other hand, if a jam was observed outside of rush hours or typical areas, then it would likely be â€œabnormal.â€
3) Description of the Experiments: Treating Waze jams as a counterpart of the network ï¬‚ows in Sec. V-C, we
implement the robust Hoeffding test on the quantized jam data in the following experiments.
Consider an area around the Boston University (BU) bridge, whose location is speciï¬ed by latitude and longitude
(42.351848, âˆ’71.110730) (see the green marker in Fig. 7). Extract the jam data no farther than 3 kilometers from
August 22, 2017
DRAFT
20
Fig. 7: Location cluster centers and detected abnormal jams for a circle area around Boston University.
BU (within the circle in Fig. 7). Note that it is possible for Waze to report several jams at the same time. To assign
each jam a unique time stamp, we slightly perturb the start time of the jams that share the same time stamp in the
raw data. Such slight adjustments would not alter the original data signiï¬cantly.
Reference (resp., test) data are taken as jams reported on March 9, 2016 (resp., March 16, 2016). Both dates
are Wednesdays, representing typical workdays. There are 3218 jams in the reference data, and 3882 jams in the
test data. Note that we have historical data for a relatively long time period (compared to the test data within a
detection window); including all the jams reported within the selected reference time period would not hurt the
accuracy of the PLs (anomaly-free ideally) to be estimated.
The features that we use for anomaly detection are location, speed, delay, and length. The time stamp of a jam
is taken as its start time. To quantize the location, we need to deï¬ne the distance between two jams. For any valid
index i, denote the complete location data of jam i by
c
loc[i] = {(xi,1, yi,1), . . . , (xi,in, yi,in)},
(29)
where xâ€™s and yâ€™s denote the latitudes and longitudes, respectively, and in is the number of points in jam i (typically,
in is greater than 4). Noting that most of the jams are approximately linear in shape, we simplify (29) by using
the 4 vertices of the â€œsmallestâ€ rectangle that covers all the points in the jam and update (29) by
loc[i] = {(xi,min, yi,min), (xi,min, yi,max),
(xi,max, yi,min), (xi,max, yi,max)},
(30)
where xi,min = min{xi,1, . . . , xi,in}, xi,max = max{xi,1, . . . , xi,in}, yi,min = min{yi,1, . . . , yi,in}, and yi,max =
max{yi,1, . . . , yi,in}. Note that loc[i] in (30) only contains 4 points. Denote the point-to-point distance (in meters)
yielded by Vincentyâ€™s formula [27] as dV (Â·, Â·). Then, for any pair of jams, say, indexed i and j, we deï¬ne the
distance between them as
min{dV (z1, z2); âˆ€z1 âˆˆloc[i], z2 âˆˆloc[j]}.
Using the distance deï¬ned above and setting the quantization level for â€œlocationâ€ as 3, we apply the commonly
used K-means clustering method [28], thus obtaining 3 cluster centers as depicted in Fig. 7 (note that, by (30) each
cluster center is represented by 4 red markers).
August 22, 2017
DRAFT
21
TABLE III: Key features of the detected abnormal jams.
index
start time
detected time
latitude
longitude
delay (in seconds)
length (in meters)
alert type
788
12:25:0.302
12:30:0.0
42.361951
-71.117963
232.0
3568.0
heavy trafï¬c
1502
15:35:0.072
15:40:0.0
42.356275
-71.119852
585.0
844.0
heavy trafï¬c
2412
19:25:0.365
19:30:0.0
42.342549
-71.085011
643.0
3568.0
heavy trafï¬c
3005
21:25:0.238
21:30:0.0
42.349125
-71.10778
168.0
1962.0
weather hazard
3094
21:35:0.267
21:40:0.0
42.373336
-71.097731
509.0
897.0
road closed
3126
21:35:0.326
21:40:0.0
42.355048
-71.110335
528.0
1293.0
heavy trafï¬c
0
200
400
600
800
1000
1200
1400
time (min)
0
2
4
6
8
divergence
(a) delay
0
200
400
600
800
1000
1200
1400
time (min)
0
2
4
6
8
10
divergence
(b) length
Fig. 8: Initial detection results for Waze jams.
In all our experiments, we take the quantization level to be 1 for â€œspeed,â€ and set the target false alarm rate as
Î² = 0.001. The window size is taken as ws = 10 minutes, and the distance between two consecutive windows is
wd = 5 minutes. To estimate the PLs, we divide a whole day into 4 subintervals: 5:00-10:00 (AM), 10:00-15:00
(MD), 15:00-19:00 (PM), and 19:00-5:00 (NT). So, for each scenario we end up with 4 PLs, corresponding to
the AM peak, the middle day, the PM peak, and the night, respectively. To calculate the threshold Î·wc
n,Î² for each
detection window, we use Alg. 2.
4) Detection Results: First, let the quantization level for â€œdelayâ€ be 2 and for â€œlengthâ€ be 1. The original sample
path has N = 3 Ã— 1 Ã— 2 Ã— 1 = 6 states. Thus, we have N 2 = 36 states in the transformed chain. We use
relatively sparse quantization levels for â€œdelayâ€ and â€œlengthâ€ to avoid unnecessary computational overhead in the
quantization subroutine for the jam location data. After running our algorithm in the initial step, 910 out of 3882
jams are reported within abnormal detection windows, which correspond to the red segments in Fig. 8a. We then
perform a reï¬nement procedure by selecting jams in these windows with non-typical individual features as follows.
For each selected feature, we calculate the sample mean Âµ and sample standard deviation Ïƒ using the reference
data. We then label as anomalous any jam with feature value exceeding Âµ+3Ïƒ. We ï¬rst consider the delay feature.
Using the 3Ïƒ-rule on delay, we obtain an anomaly list L1 containing 4 jams.
Second, let the quantization level for â€œdelayâ€ be 1 and for â€œlengthâ€ be 2. Then, again, the original sample path has
N = 3 Ã— 1 Ã— 1 Ã— 2 = 6 states, and we have N 2 = 36 states in the transformed chain. After rerunning the algorithm
in the initial step, 590 out of 3882 jams are reported within abnormal detection windows, which correspond to
the red segments in Fig. 8b, and, after reï¬ning by use of the 3Ïƒ-rule on the feature â€œlengthâ€, we end up with an
anomaly list L2 containing 2 jams.
Finally, we take L = L1 âˆªL2 as our ultimate anomaly list, which contains 6 jams in total. By checking the
August 22, 2017
DRAFT
22
time stamps and the alarm instances, we see that all of these 6 jams would be reported as abnormal by our method
within 5 minutes from their start time; this is satisfactory in a real-time trafï¬c jam anomaly detection application.
Note that we can tune wd and ws such that the detection becomes even faster while maintaining good accuracy
in identifying anomalies. Speciï¬cally, smaller wd leads to faster detection while ws should be reasonably big (the
number of jams in a window should at least be comparable to N 2). By comparing the locations and time stamps,
we map the jams in the ï¬nal anomaly list to the alert data J3, and ï¬nd that one of them was reported by Wazers
as â€œroad closed,â€ another as â€œweather hazard,â€ and all the others as â€œjam heavy trafï¬c.â€ In addition, all of them
occurred during non-peak hours. We list the key features of these abnormal jams in Tab. III, where the atypical
values of the features â€œdelayâ€ and â€œlengthâ€ have been highlighted in bold red. It is worth pointing out that jam 2412
is reported as abnormal based on â€œdelay,â€ but its length (highlighted in bold magenta) is also above the threshold
for reï¬ning the detection results based on â€œlength.â€ Note also that the latitude and longitude in each row of Tab.
III represent the closest location of the Wazer who reported the alert for the corresponding jam (extracted from the
alert data J3); the shapes of the actual jams have been visualized as colored bold curves in Fig. 7. While in this
application we do not have ground truth, it is reassuring that the jams we identify as anomalous have indeed been
reported as non-typical by Wazers. Clearly, depending on how such a detection scheme will be used by a Cityâ€™s
transportation department, our approach provides ï¬‚exibility in setting thresholds to adjust the volume of reported
anomalous jams. This volume will largely depend on the resources that City personnel have to further investigate
anomalous jams (e.g., using cameras) and intervene.
Remark 7 If we directly apply the 3Ïƒ-rule on the whole test data without implementing the Hoeffding test to
obtain a potential anomaly list ï¬rst, then we would very likely end up with too many anomalies, which might
include undesirable false alarms. Indeed, when we apply the 3Ïƒ-rule on the whole test data for â€œdelayâ€ (resp.,
â€œlengthâ€), we obtain 38 (resp., 62) â€œanomalies,â€ which are much more than those in our ï¬nal anomaly list (6 only).
Thus, including the well-validated Hoeffding test in our method ensures a good control of false alarms.
VI. CONCLUSIONS AND FUTURE WORK
We have established weak convergence results for the relative entropy in the Hoeffding test under Markovian
assumptions, which enables us to obtain a tighter estimator (compared to the existing estimator based on Sanovâ€™s
theorem) for the threshold needed by the test. We have demonstrated good performance of our estimator by
applying the Hoeffding test in extensive numerical experiments for the purpose of statistical anomaly detection. The
application scenarios involve not only simulated communication networks, but also real transportation networks.
Our work contributes to enhancing cyber security and helping build smarter cities.
As for future work, it is of interest to establish theoretical comparison results concerning the tightness of the
threshold estimators. The challenge in this direction arises from associating the ï¬nite sample-size setting with the
asymptotic properties of the Central Limit Theorem and the large deviations results (Sanovâ€™s theorem). It is also
of interest to conduct rigorous analysis relating the computation time of the proposed estimation approach to its
accuracy. Also, it is possible to consider additional applications.
August 22, 2017
DRAFT
23
APPENDIX A
PROOF OF LEMMA 1
Expanding the ï¬rst N entries of Ï€P = Ï€, we obtain q1i
PN
t=1 Ï€t1 = Ï€1i, i = 1, . . . , N. Summing up both sides
of these equations, it follows
 XN
i=1 q1i
 XN
t=1 Ï€t1

=
XN
t=1 Ï€1t.
(A.1)
Noticing PN
i=1 q1i = 1, (A.1) implies PN
t=1 Ï€t1 = PN
t=1 Ï€1t, which, together with q11
PN
t=1 Ï€t1 = Ï€11, yields
Ï€11
PN
t=1 Ï€1t
=
Ï€11
PN
t=1 Ï€t1
= q11.
Similarly, we can show (9) holds for all the other (i, j)â€™s.
APPENDIX B
PROOF OF LEMMA 2
This can be established by applying [15, Corollary 1]. Noting fk(Â·) is an indicator function, thus Borel measurable
and bounded, and the chain Z is uniformly ergodic, we see that, âˆƒB âˆˆ(0, âˆ) s.t. |fk(Z)| â‰¤B, âˆ€Z, implying that
E[|fk(Z)|3] â‰¤B3 < âˆ, and [15, (3)] holds with M(Â·) bounded, leading to E[M] < âˆ, and Î³(n) = tn for some
t âˆˆ(0, 1), indicating that P
n (Î³(n))1/.3 = P
n tn/.3 = P
n (t1/.3)
n < âˆ. Thus, all the conditions needed by [15,
Corollary 1] are satisï¬ed.
APPENDIX C
PROOF OF LEMMA 3
We can directly extend Lemma 2 to the multidimensional case (see [29, Chap. 8]). In particular, under Assumption
1, (12) holds with Î› given by
Î› = Î›
(0) +
Xâˆ
m=1 Î›
(m),
(C.1)
where Î›(0) and Î›(m) are speciï¬ed, respectively, by
Î›
(0) =[Cov(fi(Z1), fj(Z1))]N2
i, j=1,
Î›
(m) =[Cov(fi(Z1), fj(Z1+m))
+ Cov(fj(Z1), fi(Z1+m))]N2
i, j=1,
m = 1, 2, . . . .
Let the subscript ij denote the (i, j) elements of the matrices Î›, Î›(0), Î›(m). By the Markovian properties, after
some direct algebra, for i, j = 1, . . . , N 2 we obtain Î›
(0)
ij = ËœÏ€i(Iij âˆ’ËœÏ€j) and
Î›
(m)
ij
= ËœÏ€i(Pm
ij âˆ’ËœÏ€j) + ËœÏ€j(Pm
ji âˆ’ËœÏ€i),
m = 1, 2, . . . .
ACKNOWLEDGMENTS
We thank Jing Wang for his contributions and help in developing the software package SADIT [8]. We also
thank the DoIT of the City of Boston, Chris Osgood, Alex Chen, and Connor McKay for supplying the Waze data.
We thank Athanasios Tsiligkaridis for his help in deriving Tab. III in Sec. V-D. We ï¬nally thank the anonymous
reviewers for useful comments on preliminary versions of this paper.
August 22, 2017
DRAFT
24
REFERENCES
[1] I. C. Paschalidis and G. Smaragdakis, â€œSpatio-temporal network anomaly detection by assessing deviations of empirical measures,â€
IEEE/ACM Transactions on Networking (TON), vol. 17, no. 3, pp. 685â€“697, 2009.
[2] S. Meyn, A. Surana, Y. Lin, and S. Narayanan, â€œAnomaly detection using projective Markov models in a distributed sensor network,â€ in
Proceedings of the 48th IEEE Conference on Decision and Control, 2009 held jointly with the 2009 28th Chinese Control Conference.
CDC/CCC 2009., Dec 2009, pp. 4662â€“4669.
[3] J. Wang, D. Rossell, C. G. Cassandras, and I. C. Paschalidis, â€œNetwork anomaly detection: A survey and comparative analysis of stochastic
and deterministic methods,â€ in IEEE 52nd Annual Conference on Decision and Control (CDC), Dec 2013, pp. 182â€“187.
[4] J. Wang and I. Paschalidis, â€œStatistical trafï¬c anomaly detection in time-varying communication networks,â€ IEEE Transactions on Control
of Network Systems, vol. 2, no. 2, pp. 100â€“111, 2015.
[5] J. Unnikrishnan and D. Huang, â€œWeak convergence analysis of asymptotically optimal hypothesis tests,â€ IEEE Transactions on Information
Theory, vol. 62, no. 7, pp. 4285â€“4299, 2016.
[6] W. Hoeffding, â€œAsymptotically optimal tests for multinomial distributions,â€ The Annals of Mathematical Statistics, pp. 369â€“401, 1965.
[7] A. Dembo and O. Zeitouni, Large deviations techniques and applications.
Springer, 1998.
[8] J. Wang, J. Zhang, and I. C. Paschalidis, â€œSystematic Anomaly Detection of Internet Trafï¬c (SADIT),â€ https://github.com/hbhzwj/SADIT,
2014.
[9] J. Zhang and I. C. Paschalidis, â€œAn improved composite hypothesis test for markov models with applications in network anomaly detection,â€
in 2015 54th IEEE Conference on Decision and Control (CDC).
IEEE, 2015, pp. 3810â€“3815.
[10] J. Unnikrishnan, D. Huang, S. P. Meyn, A. Surana, and V. V. Veeravalli, â€œUniversal and composite hypothesis testing via mismatched
divergence,â€ IEEE Transactions on Information Theory, vol. 57, no. 3, pp. 1587â€“1603, 2011.
[11] S. S. Wilks, â€œThe large-sample distribution of the likelihood ratio for testing composite hypotheses,â€ The Annals of Mathematical Statistics,
vol. 9, no. 1, pp. 60â€“62, 1938.
[12] M. Iltis, â€œSharp asymptotics of large deviations in Rd,â€ Journal of Theoretical Probability, vol. 8, no. 3, pp. 501â€“522, 1995.
[13] M. Thottan and C. Ji, â€œAnomaly detection in ip networks,â€ IEEE Transactions on Signal Processing, vol. 51, no. 8, pp. 2191â€“2204, Aug
2003.
[14] T. Fawcett, â€œAn introduction to ROC analysis,â€ Pattern recognition letters, vol. 27, no. 8, pp. 861â€“874, 2006.
[15] G. L. Jones, â€œOn the Markov chain central limit theorem,â€ Probability Surveys, vol. 1, pp. 299â€“320, 2004.
[16] P. Billingsley, â€œStatistical methods in markov chains,â€ The Annals of Mathematical Statistics, pp. 12â€“40, 1961.
[17] â€”â€”, Convergence of probability measures.
John Wiley & Sons, 2013.
[18] J. Imhof, â€œComputing the distribution of quadratic forms in normal variables,â€ Biometrika, vol. 48, no. 3/4, pp. 419â€“426, 1961.
[19] H. Liu, Y. Tang, and H. H. Zhang, â€œA new chi-square approximation to the distribution of non-negative deï¬nite quadratic forms in
non-central normal variables,â€ Computational Statistics & Data Analysis, vol. 53, no. 4, pp. 853â€“856, 2009.
[20] P. Billingsley, Statistical inference for Markov processes.
University of Chicago Press, 1961.
[21] M. L. MenÂ´endez, D. Morales, L. Pardo, and I. Vajda, â€œTesting in stationary models based on divergences of observed and theoretical
frequencies,â€ Kybernetika, vol. 33, no. 5, pp. 465â€“475, 1997.
[22] â€”â€”, â€œInference about stationary distributions of markov chains based on divergences with observed frequencies,â€ Kybernetika, vol. 35,
no. 3, pp. 265â€“280, 1999.
[23] J. Zhang, â€œThreshold Approximation for Hoeffdingâ€™s Test under Markovian Assumption (TAM),â€ https://github.com/jingzbu/TAHTMA,
2015.
[24] C. Pandit and S. Meyn, â€œWorst-case large-deviation asymptotics with application to queueing and information theory,â€ Stochastic processes
and their applications, vol. 116, no. 5, pp. 724â€“756, 2006.
[25] J. Zhang, â€œROC analysis for Hoeffding test under Markovian assumptions (ROM),â€ https://github.com/jingzbu/ROCHM, 2017.
[26] J. Sommers, R. Bowden, B. Eriksson, P. Barford, M. Roughan, and N. Dufï¬eld, â€œEfï¬cient network-wide ï¬‚ow record generation,â€ in
INFOCOM, 2011 Proceedings IEEE.
IEEE, 2011, pp. 2363â€“2371.
[27] Wikipedia, â€œVincentyâ€™s formulae,â€ https://en.wikipedia.org/wiki/Vincenty%27s formulae.
[28] â€”â€”, â€œk-means clustering,â€ https://en.wikipedia.org/wiki/K-means clustering.
[29] C. Geyer, â€œStat 5101 (Geyer) Course Notes,â€ http://www.stat.umn.edu/geyer/5101/notes/n2.pdf, 2001.
August 22, 2017
DRAFT
